{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "TensorFlow 2.4 on Python 3.8 & CUDA 11.1",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "3.5-classifying-newswires.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/K-107/deep-learning-with-python-notebooks/blob/tf2/3.5-classifying-newswires.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKG6_mHPG0pR",
        "outputId": "06013f4e-eb33-4d69-8477-476c4da981ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from tensorflow import keras\n",
        "keras.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.6.0'"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxGDbe3zG0pT"
      },
      "source": [
        "# 뉴스 기사 분류: 다중 분류 문제\n",
        "\n",
        "이 노트북은 [케라스 창시자에게 배우는 딥러닝](https://tensorflow.blog/케라스-창시자에게-배우는-딥러닝/) 책의 3장 5절의 코드 예제입니다. 책에는 더 많은 내용과 그림이 있습니다. 이 노트북에는 소스 코드에 관련된 설명만 포함합니다. 이 노트북의 설명은 케라스 버전 2.2.2에 맞추어져 있습니다. 케라스 최신 버전이 릴리스되면 노트북을 다시 테스트하기 때문에 설명과 코드의 결과가 조금 다를 수 있습니다.\n",
        "\n",
        "----\n",
        "\n",
        "이전 섹션에서 완전 연결된 신경망을 사용해 벡터 입력을 어떻게 두 개의 클래스로 분류하는지 보았습니다. 두 개 이상의 클래스가 있을 때는 어떻게 해야 할까요?\n",
        "\n",
        "이 절에서 로이터 뉴스를 46개의 상호 배타적인 토픽으로 분류하는 신경망을 만들어 보겠습니다. 클래스가 많기 때문에 이 문제는 다중 분류의 예입니다. 각 데이터 포인트가 정확히 하나의 범주로 분류되기 때문에 좀 더 정확히 말하면 단일 레이블 다중 분류 문제입니다. 각 데이터 포인트가 여러 개의 범주(가령, 토픽)에 속할 수 있다면 이런 문제는 다중 레이블 다중 분류의 문제가 됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnx4Nu6gG0pV"
      },
      "source": [
        "## 로이터 데이터셋\n",
        "\n",
        "1986년에 로이터에서 공개한 짧은 뉴스 기사와 토픽의 집합인 로이터 데이터셋을 사용하겠습니다. 이 데이터셋은 텍스트 분류를 위해 널리 사용되는 간단한 데이터셋입니다. 46개의 토픽이 있으며 어떤 토픽은 다른 것에 비해 데이터가 많습니다. 각 토픽은 훈련 세트에 최소한 10개의 샘플을 가지고 있습니다.\n",
        "\n",
        "IMDB와 MNIST와 마찬가지로 로이터 데이터셋은 케라스에 포함되어 있습니다. 한 번 살펴보죠:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfD1y1IBG0pV",
        "outputId": "507008d0-4daa-468f-e82f-93fdede1b4ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from tensorflow.keras.datasets import reuters\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
            "2113536/2110848 [==============================] - 0s 0us/step\n",
            "2121728/2110848 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPKeIyMbG0pW"
      },
      "source": [
        "IMDB 데이터셋에서처럼 num_words=10000 매개변수는 데이터에서 가장 자주 등장하는 단어 10,000개로 제한합니다.\n",
        "\n",
        "여기에는 8,982개의 훈련 샘플과 2,246개의 테스트 샘플이 있습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioafCZArLPc9",
        "outputId": "63f69b94-bc78-4956-99c5-093fb692646f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_data"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list([1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]),\n",
              "       list([1, 3267, 699, 3434, 2295, 56, 2, 7511, 9, 56, 3906, 1073, 81, 5, 1198, 57, 366, 737, 132, 20, 4093, 7, 2, 49, 2295, 2, 1037, 3267, 699, 3434, 8, 7, 10, 241, 16, 855, 129, 231, 783, 5, 4, 587, 2295, 2, 2, 775, 7, 48, 34, 191, 44, 35, 1795, 505, 17, 12]),\n",
              "       list([1, 53, 12, 284, 15, 14, 272, 26, 53, 959, 32, 818, 15, 14, 272, 26, 39, 684, 70, 11, 14, 12, 3886, 18, 180, 183, 187, 70, 11, 14, 102, 32, 11, 29, 53, 44, 704, 15, 14, 19, 758, 15, 53, 959, 47, 1013, 15, 14, 19, 132, 15, 39, 965, 32, 11, 14, 147, 72, 11, 180, 183, 187, 44, 11, 14, 102, 19, 11, 123, 186, 90, 67, 960, 4, 78, 13, 68, 467, 511, 110, 59, 89, 90, 67, 1390, 55, 2678, 92, 617, 80, 1274, 46, 905, 220, 13, 4, 346, 48, 235, 629, 5, 211, 5, 1118, 7, 2, 81, 5, 187, 11, 15, 9, 1709, 201, 5, 47, 3615, 18, 478, 4514, 5, 1118, 7, 232, 2, 71, 5, 160, 63, 11, 9, 2, 81, 5, 102, 59, 11, 17, 12]),\n",
              "       ...,\n",
              "       list([1, 141, 3890, 387, 81, 8, 16, 1629, 10, 340, 1241, 850, 31, 56, 3890, 691, 9, 1241, 71, 9, 5985, 2, 2, 699, 2, 2, 2, 699, 244, 5945, 4, 49, 8, 4, 656, 850, 33, 2993, 9, 2139, 340, 3371, 1493, 9, 2, 22, 2, 1094, 687, 83, 35, 15, 257, 6, 57, 9190, 7, 4, 5956, 654, 5, 2, 6191, 1371, 4, 49, 8, 16, 369, 646, 6, 1076, 7, 124, 407, 17, 12]),\n",
              "       list([1, 53, 46, 957, 26, 14, 74, 132, 26, 39, 46, 258, 3614, 18, 14, 74, 134, 5131, 18, 88, 2321, 72, 11, 14, 1842, 32, 11, 123, 383, 89, 39, 46, 235, 10, 864, 728, 5, 258, 44, 11, 15, 22, 753, 9, 42, 92, 131, 728, 5, 69, 312, 11, 15, 22, 222, 2, 3237, 383, 48, 39, 74, 235, 10, 864, 276, 5, 61, 32, 11, 15, 21, 4, 211, 5, 126, 1072, 42, 92, 131, 46, 19, 352, 11, 15, 22, 710, 220, 9, 42, 92, 131, 276, 5, 59, 61, 11, 15, 22, 10, 455, 7, 1172, 137, 336, 1325, 6, 1532, 142, 971, 6463, 43, 359, 5, 4, 326, 753, 364, 17, 12]),\n",
              "       list([1, 227, 2406, 91, 2, 125, 2855, 21, 4, 3976, 76, 7, 4, 757, 481, 3976, 790, 5259, 5654, 9, 111, 149, 8, 7, 10, 76, 223, 51, 4, 417, 8, 1047, 91, 6917, 1688, 340, 7, 194, 9411, 6, 1894, 21, 127, 2151, 2394, 1456, 6, 3034, 4, 329, 433, 7, 65, 87, 1127, 10, 8219, 1475, 290, 9, 21, 567, 16, 1926, 24, 4, 76, 209, 30, 4033, 6655, 5654, 8, 4, 60, 8, 4, 966, 308, 40, 2575, 129, 2, 295, 277, 1071, 9, 24, 286, 2114, 234, 222, 9, 4, 906, 3994, 8519, 114, 5758, 1752, 7, 4, 113, 17, 12])],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ogk-dwVHG0pW",
        "outputId": "2b48696a-7d77-4a7b-c02a-c663d758a9fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(train_data), train_labels, max(train_labels)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8982, array([ 3,  4,  3, ..., 25,  3, 25]), 45)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPi_RjJ8J2H0",
        "outputId": "b8f330b6-0082-452b-bef0-8f36b9e6d1ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dic = {}\n",
        "\n",
        "for label in train_labels:\n",
        "  if label in dic:\n",
        "    dic[label] = dic[label] + 1\n",
        "  else:\n",
        "    dic[label] = 1\n",
        "\n",
        "dic"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 55,\n",
              " 1: 432,\n",
              " 2: 74,\n",
              " 3: 3159,\n",
              " 4: 1949,\n",
              " 5: 17,\n",
              " 6: 48,\n",
              " 7: 16,\n",
              " 8: 139,\n",
              " 9: 101,\n",
              " 10: 124,\n",
              " 11: 390,\n",
              " 12: 49,\n",
              " 13: 172,\n",
              " 14: 26,\n",
              " 15: 20,\n",
              " 16: 444,\n",
              " 17: 39,\n",
              " 18: 66,\n",
              " 19: 549,\n",
              " 20: 269,\n",
              " 21: 100,\n",
              " 22: 15,\n",
              " 23: 41,\n",
              " 24: 62,\n",
              " 25: 92,\n",
              " 26: 24,\n",
              " 27: 15,\n",
              " 28: 48,\n",
              " 29: 19,\n",
              " 30: 45,\n",
              " 31: 39,\n",
              " 32: 32,\n",
              " 33: 11,\n",
              " 34: 50,\n",
              " 35: 10,\n",
              " 36: 49,\n",
              " 37: 19,\n",
              " 38: 19,\n",
              " 39: 24,\n",
              " 40: 36,\n",
              " 41: 30,\n",
              " 42: 13,\n",
              " 43: 21,\n",
              " 44: 12,\n",
              " 45: 18}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daHxYqCCG0pX",
        "outputId": "e47bce6d-28e2-4c6a-ef89-bfc81122518e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(test_data)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2246"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHUOkEzpG0pY"
      },
      "source": [
        "IMDB 리뷰처럼 각 샘플은 정수 리스트입니다(단어 인덱스):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtafVPgIG0pY",
        "outputId": "459a0c33-26fc-4064-91c2-7e13d250042b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_data[10]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 245,\n",
              " 273,\n",
              " 207,\n",
              " 156,\n",
              " 53,\n",
              " 74,\n",
              " 160,\n",
              " 26,\n",
              " 14,\n",
              " 46,\n",
              " 296,\n",
              " 26,\n",
              " 39,\n",
              " 74,\n",
              " 2979,\n",
              " 3554,\n",
              " 14,\n",
              " 46,\n",
              " 4689,\n",
              " 4329,\n",
              " 86,\n",
              " 61,\n",
              " 3499,\n",
              " 4795,\n",
              " 14,\n",
              " 61,\n",
              " 451,\n",
              " 4329,\n",
              " 17,\n",
              " 12]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6Hbm69SG0pZ"
      },
      "source": [
        "궁금한 경우를 위해 어떻게 단어로 디코딩하는지 알아보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8FVpEuTG0pZ",
        "outputId": "fd45ae22-81a7-4b73-ad8f-65359d9c15d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "word_index = reuters.get_word_index()\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "# 0, 1, 2는 '패딩', '문서 시작', '사전에 없음'을 위한 인덱스이므로 3을 뺍니다\n",
        "decoded_newswire = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters_word_index.json\n",
            "557056/550378 [==============================] - 0s 0us/step\n",
            "565248/550378 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ragoUHgWG0pZ",
        "outputId": "58129406-0c9e-43e8-e94e-4975702fa78a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "decoded_newswire"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3'"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWqRLq1OG0pa"
      },
      "source": [
        "샘플에 연결된 레이블은 토픽의 인덱스로 0과 45 사이의 정수입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nORwZTwbG0pa",
        "outputId": "90481c1c-df13-49a5-d10c-52e29e38f3b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_labels[10]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-wPYYFqG0pa"
      },
      "source": [
        "## 데이터 준비\n",
        "\n",
        "이전의 예제와 동일한 코드를 사용해서 데이터를 벡터로 변환합니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zZuQgVoG0pb"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i, sequence] = 1.\n",
        "    return results\n",
        "\n",
        "# 훈련 데이터 벡터 변환\n",
        "x_train = vectorize_sequences(train_data)\n",
        "# 테스트 데이터 벡터 변환\n",
        "x_test = vectorize_sequences(test_data)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hGlqV5nG0pb"
      },
      "source": [
        "레이블을 벡터로 바꾸는 방법은 두 가지입니다. 레이블의 리스트를 정수 텐서로 변환하는 것과 원-핫 인코딩을 사용하는 것입니다. 원-핫 인코딩이 범주형 데이터에 널리 사용되기 때문에 범주형 인코딩이라고도 부릅니다. 원-핫 인코딩에 대한 자세한 설명은 6.1절을 참고하세요. 이 경우 레이블의 원-핫 인코딩은 각 레이블의 인덱스 자리는 1이고 나머지는 모두 0인 벡터입니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhvoRJupG0pb"
      },
      "source": [
        "def to_one_hot(labels, dimension=46):\n",
        "    results = np.zeros((len(labels), dimension))\n",
        "    for i, label in enumerate(labels):\n",
        "        results[i, label] = 1.\n",
        "    return results\n",
        "\n",
        "# 훈련 레이블 벡터 변환\n",
        "one_hot_train_labels = to_one_hot(train_labels)\n",
        "# 테스트 레이블 벡터 변환\n",
        "one_hot_test_labels = to_one_hot(test_labels)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQGJ1_M5G0pb"
      },
      "source": [
        "MNIST 예제에서 이미 보았듯이 케라스에는 이를 위한 내장 함수가 있습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmP6-BPKG0pb"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "one_hot_train_labels = to_categorical(train_labels)\n",
        "one_hot_test_labels = to_categorical(test_labels)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4K1BPDsG0pb"
      },
      "source": [
        "## 모델 구성\n",
        "\n",
        "이 토픽 분류 문제는 이전의 영화 리뷰 분류 문제와 비슷해 보입니다. 두 경우 모두 짧은 텍스트를 분류하는 것이죠. 여기에서는 새로운 제약 사항이 추가되었습니다. 출력 클래스의 개수가 2에서 46개로 늘어난 점입니다. 출력 공간의 차원이 훨씬 커졌습니다.\n",
        "\n",
        "이전에 사용했던 것처럼 `Dense` 층을 쌓으면 각 층은 이전 층의 출력에서 제공한 정보만 사용할 수 있습니다. 한 층이 분류 문제에 필요한 일부 정보를 누락하면 그 다음 층에서 이를 복원할 방법이 없습니다. 각 층은 잠재적으로 정보의 병목이 될 수 있습니다. 이전 예제에서 16차원을 가진 중간층을 사용했지만 16차원 공간은 46개의 클래스를 구분하기에 너무 제약이 많을 것 같습니다. 이렇게 규모가 작은 층은 유용한 정보를 완전히 잃게 되는 정보의 병목 지점처럼 동작할 수 있습니다.\n",
        "\n",
        "이런 이유로 좀 더 규모가 큰 층을 사용하겠습니다. 64개의 유닛을 사용해 보죠:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAFymW5iG0pc"
      },
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(46, activation='softmax'))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bE1gT0iBG0pc"
      },
      "source": [
        "이 구조에서 주목해야 할 점이 두 가지 있습니다:\n",
        "\n",
        "* 마지막 `Dense` 층의 크기가 46입니다. 각 입력 샘플에 대해서 46차원의 벡터를 출력한다는 뜻입니다. 이 벡터의 각 원소(각 차원)은 각기 다른 출력 클래스가 인코딩된 것입니다.\n",
        "* 마지막 층에 `softmax` 활성화 함수가 사용되었습니다. MNIST 예제에서 이런 방식을 보았습니다. 각 입력 샘플마다 46개의 출력 클래스에 대한 확률 분포를 출력합니다. 즉, 46차원의 출력 벡터를 만들며 `output[i]`는 어떤 샘플이 클래스 `i`에 속할 확률입니다. 46개의 값을 모두 더하면 1이 됩니다.\n",
        "\n",
        "이런 문제에 사용할 최선의 손실 함수는 `categorical_crossentropy`입니다. 이 함수는 두 확률 분포의 사이의 거리를 측정합니다. 여기에서는 네트워크가 출력한 확률 분포와 진짜 레이블의 분포 사이의 거리입니다. 두 분포 사이의 거리를 최소화하면 진짜 레이블에 가능한 가까운 출력을 내도록 모델을 훈련하게 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBY9OuMHG0pc"
      },
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrCx-IwcG0pc"
      },
      "source": [
        "## 훈련 검증\n",
        "\n",
        "훈련 데이터에서 1,000개의 샘플을 따로 떼어서 검증 세트로 사용하겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-or0eYyG0pc"
      },
      "source": [
        "x_val = x_train[:1000]\n",
        "partial_x_train = x_train[1000:]\n",
        "\n",
        "y_val = one_hot_train_labels[:1000]\n",
        "partial_y_train = one_hot_train_labels[1000:]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7w2QcPUG0pc"
      },
      "source": [
        "이제 20번의 에포크로 모델을 훈련시킵니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "Rj5enLUUG0pc",
        "outputId": "8c57894b-0e43-4284-d565-ad080390d797",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "16/16 [==============================] - 3s 31ms/step - loss: 2.6183 - accuracy: 0.5124 - val_loss: 1.7231 - val_accuracy: 0.6350\n",
            "Epoch 2/20\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 1.4166 - accuracy: 0.7020 - val_loss: 1.3158 - val_accuracy: 0.7180\n",
            "Epoch 3/20\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 1.0505 - accuracy: 0.7790 - val_loss: 1.1467 - val_accuracy: 0.7670\n",
            "Epoch 4/20\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.8289 - accuracy: 0.8226 - val_loss: 1.0509 - val_accuracy: 0.7840\n",
            "Epoch 5/20\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.6518 - accuracy: 0.8632 - val_loss: 0.9682 - val_accuracy: 0.8050\n",
            "Epoch 6/20\n",
            "16/16 [==============================] - 0s 19ms/step - loss: 0.5215 - accuracy: 0.8939 - val_loss: 0.9414 - val_accuracy: 0.8150\n",
            "Epoch 7/20\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.4138 - accuracy: 0.9161 - val_loss: 0.9101 - val_accuracy: 0.8140\n",
            "Epoch 8/20\n",
            "16/16 [==============================] - 0s 20ms/step - loss: 0.3355 - accuracy: 0.9305 - val_loss: 0.9100 - val_accuracy: 0.8130\n",
            "Epoch 9/20\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.2751 - accuracy: 0.9407 - val_loss: 0.9121 - val_accuracy: 0.8150\n",
            "Epoch 10/20\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.2376 - accuracy: 0.9460 - val_loss: 0.9125 - val_accuracy: 0.8190\n",
            "Epoch 11/20\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.1987 - accuracy: 0.9523 - val_loss: 0.9335 - val_accuracy: 0.8170\n",
            "Epoch 12/20\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.1768 - accuracy: 0.9520 - val_loss: 0.9527 - val_accuracy: 0.8070\n",
            "Epoch 13/20\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.1590 - accuracy: 0.9548 - val_loss: 0.9592 - val_accuracy: 0.8060\n",
            "Epoch 14/20\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.1485 - accuracy: 0.9538 - val_loss: 1.0446 - val_accuracy: 0.7940\n",
            "Epoch 15/20\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.1374 - accuracy: 0.9565 - val_loss: 0.9812 - val_accuracy: 0.8150\n",
            "Epoch 16/20\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.1299 - accuracy: 0.9567 - val_loss: 0.9967 - val_accuracy: 0.8080\n",
            "Epoch 17/20\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.1261 - accuracy: 0.9564 - val_loss: 1.0202 - val_accuracy: 0.8130\n",
            "Epoch 18/20\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.1229 - accuracy: 0.9562 - val_loss: 1.0474 - val_accuracy: 0.8060\n",
            "Epoch 19/20\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.1124 - accuracy: 0.9577 - val_loss: 1.0708 - val_accuracy: 0.8070\n",
            "Epoch 20/20\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1099 - accuracy: 0.9573 - val_loss: 1.1380 - val_accuracy: 0.8000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IN_oqGxkG0pd"
      },
      "source": [
        "손실과 정확도 곡선을 그려 보죠:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aY86XyjbG0pd"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzVJtukRG0pd",
        "outputId": "c753ffb1-1db9-41bc-8815-598494929644",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(loss) + 1)\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VONBdA7OG0pd",
        "outputId": "4c54e156-470c-4890-b357-d71d69aafae9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.clf()   # 그래프를 초기화합니다\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yAEAOY3G0pe"
      },
      "source": [
        "이 모델은 9번째 에포크 이후에 과대적합이 시작됩니다. 9번의 에포크로 새로운 모델을 훈련하고 테스트 세트에서 평가하겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7OW5ir2G0pe",
        "outputId": "b401aae4-d997-40ff-a4f5-bcf1a668e6be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(46, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(partial_x_train,\n",
        "          partial_y_train,\n",
        "          epochs=9,\n",
        "          batch_size=512,\n",
        "          validation_data=(x_val, y_val))\n",
        "results = model.evaluate(x_test, one_hot_test_labels)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/9\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 2.7045 - accuracy: 0.5222 - val_loss: 1.7476 - val_accuracy: 0.6590\n",
            "Epoch 2/9\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 1.4299 - accuracy: 0.7102 - val_loss: 1.2992 - val_accuracy: 0.7280\n",
            "Epoch 3/9\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 1.0430 - accuracy: 0.7801 - val_loss: 1.1174 - val_accuracy: 0.7630\n",
            "Epoch 4/9\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.8150 - accuracy: 0.8299 - val_loss: 1.0288 - val_accuracy: 0.7770\n",
            "Epoch 5/9\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.6473 - accuracy: 0.8661 - val_loss: 0.9691 - val_accuracy: 0.8020\n",
            "Epoch 6/9\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.5178 - accuracy: 0.8961 - val_loss: 0.9190 - val_accuracy: 0.8070\n",
            "Epoch 7/9\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.4157 - accuracy: 0.9154 - val_loss: 0.8986 - val_accuracy: 0.8090\n",
            "Epoch 8/9\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.3390 - accuracy: 0.9266 - val_loss: 0.9016 - val_accuracy: 0.8270\n",
            "Epoch 9/9\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.2826 - accuracy: 0.9380 - val_loss: 0.9005 - val_accuracy: 0.8110\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 0.9776 - accuracy: 0.7854\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dt1eHM4cG0pe",
        "outputId": "9ccae801-5ad9-4101-943a-e49a5ca9b08d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "results"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9776286482810974, 0.7853962779045105]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otMAZ9MZG0pe"
      },
      "source": [
        "대략 78%의 정확도를 달성했습니다. 균형 잡힌 이진 분류 문제에서 완전히 무작위로 분류하면 50%의 정확도를 달성합니다. 이 문제는 불균형한 데이터셋을 사용하므로 무작위로 분류하면 19% 정도를 달성합니다. 여기에 비하면 이 결과는 꽤 좋은 편입니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dry3Wss2G0pe",
        "outputId": "e341bd2e-f49b-41ae-96a7-da9fced1d5ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import copy\n",
        "\n",
        "test_labels_copy = copy.copy(test_labels)\n",
        "np.random.shuffle(test_labels_copy)\n",
        "float(np.sum(np.array(test_labels) == np.array(test_labels_copy))) / len(test_labels)\n",
        "# float로 해줘야지 계산의 정확도가 더 상승한다.\n",
        "# float가 없으면 0.18788958147818344이 나온다."
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.19323241317898487"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyhHgDTNQViQ",
        "outputId": "69ae4730-fb80-4b98-f24c-7bfd0aefb31d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# np.array(test_labels) == np.array(test_labels_copy)는 불린 값이다.\n",
        "np.array(test_labels) == np.array(test_labels_copy)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True, False, False, ...,  True, False,  True])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZ6VyeRsG0pe"
      },
      "source": [
        "## 새로운 데이터에 대해 예측하기\n",
        "\n",
        "모델 인스턴스의 `predict` 메서드는 46개 토픽에 대한 확률 분포를 반환합니다. 테스트 데이터 전체에 대한 토픽을 예측해 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqDWGfvOG0pf"
      },
      "source": [
        "predictions = model.predict(x_test)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ol-4roZG0pf"
      },
      "source": [
        "`predictions`의 각 항목은 길이가 46인 벡터입니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqW4zNmiG0pf",
        "outputId": "51e08d93-1faf-41cd-9f88-cb779ca530d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "predictions[0].shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(46,)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qnsqFIxG0pf"
      },
      "source": [
        "이 벡터의 원소 합은 1입니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlRc6Z1rG0pf",
        "outputId": "43493971-45e3-45c8-ac39-a3f544432075",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "np.sum(predictions[0])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikS_WSrHG0pf"
      },
      "source": [
        "가장 큰 값이 예측 클래스가 됩니다. 즉, 가장 확률이 높은 클래스입니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzuXc-xUG0pf",
        "outputId": "045c6f2d-cb61-4e46-b72f-9aeba7346244",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "np.argmax(predictions[0])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dehNIWqFG0pf"
      },
      "source": [
        "## 레이블과 손실을 다루는 다른 방법\n",
        "\n",
        "앞서 언급한 것처럼 레이블을 인코딩하는 다른 방법은 다음과 같이 정수 텐서로 변환하는 것입니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2acc5aiG0pf"
      },
      "source": [
        "y_train = np.array(train_labels)\n",
        "y_test = np.array(test_labels)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_OV9oROG0pf"
      },
      "source": [
        "이 방식을 사용하려면 손실 함수 하나만 바꾸면 됩니다. 코드 3-21에 사용된 손실 함수 `categorical_crossentropy`는 레이블이 범주형 인코딩되어 있을 것이라고 기대합니다. 정수 레이블을 사용할 때는 `sparse_categorical_crossentropy`를 사용해야 합니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXuqcPg_G0pg"
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0A_3UI1G0pg"
      },
      "source": [
        "이 손실 함수는 인터페이스만 다를 뿐이고 수학적으로는 `categorical_crossentropy`와 동일합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lex0TuO8G0pg"
      },
      "source": [
        "## 충분히 큰 중간층을 두어야 하는 이유\n",
        "\n",
        "앞서 언급한 것처럼 마지막 출력이 46차원이기 때문에 중간층의 히든 유닛이 46개보다 많이 적어서는 안 됩니다. 46차원보다 훨씬 작은 중간층(예를 들면 4차원)을 두면 정보의 병목이 어떻게 나타나는지 확인해 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnLrpXfdG0pg",
        "outputId": "f59dbf55-b15d-4194-a4d1-c6d479dc90da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(4, activation='relu'))\n",
        "model.add(layers.Dense(46, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(partial_x_train,\n",
        "          partial_y_train,\n",
        "          epochs=20,\n",
        "          batch_size=128,\n",
        "          validation_data=(x_val, y_val))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 1s 12ms/step - loss: 2.6641 - accuracy: 0.4936 - val_loss: 1.9124 - val_accuracy: 0.5950\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1.5999 - accuracy: 0.6655 - val_loss: 1.5000 - val_accuracy: 0.6790\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1.2772 - accuracy: 0.7189 - val_loss: 1.4009 - val_accuracy: 0.6890\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1.1223 - accuracy: 0.7383 - val_loss: 1.3421 - val_accuracy: 0.7010\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1.0178 - accuracy: 0.7567 - val_loss: 1.3296 - val_accuracy: 0.7090\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.9355 - accuracy: 0.7684 - val_loss: 1.3374 - val_accuracy: 0.7070\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.8665 - accuracy: 0.7772 - val_loss: 1.3845 - val_accuracy: 0.7060\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.8079 - accuracy: 0.7895 - val_loss: 1.3995 - val_accuracy: 0.7010\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.7566 - accuracy: 0.7993 - val_loss: 1.3878 - val_accuracy: 0.7070\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.7088 - accuracy: 0.8048 - val_loss: 1.4383 - val_accuracy: 0.7000\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6698 - accuracy: 0.8150 - val_loss: 1.4926 - val_accuracy: 0.7050\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.6323 - accuracy: 0.8325 - val_loss: 1.5176 - val_accuracy: 0.7050\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.6036 - accuracy: 0.8400 - val_loss: 1.5532 - val_accuracy: 0.7090\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.5740 - accuracy: 0.8443 - val_loss: 1.6152 - val_accuracy: 0.6980\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.5492 - accuracy: 0.8464 - val_loss: 1.6631 - val_accuracy: 0.7040\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.5266 - accuracy: 0.8512 - val_loss: 1.7423 - val_accuracy: 0.6910\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.5070 - accuracy: 0.8562 - val_loss: 1.7601 - val_accuracy: 0.6980\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.4894 - accuracy: 0.8606 - val_loss: 1.7912 - val_accuracy: 0.7020\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.4729 - accuracy: 0.8710 - val_loss: 1.8787 - val_accuracy: 0.6900\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.4569 - accuracy: 0.8735 - val_loss: 1.9204 - val_accuracy: 0.6920\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f58bd4b0950>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrpN5dD1G0pg"
      },
      "source": [
        "검증 정확도의 최고 값은 약 71%로 8% 정도 감소되었습니다. 이런 손실의 대부분 원인은 많은 정보(46개 클래스의 분할 초평면을 복원하기에 충분한 정보)를 중간층의 저차원 표현 공간으로 압축하려고 했기 때문입니다. 이 네트워크는 필요한 정보 대부분을 4차원 표현 안에 구겨 넣었지만 전부는 넣지 못했습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12jPq6wmG0pg"
      },
      "source": [
        "## 추가 실험\n",
        "\n",
        "* 더 크거나 작은 층을 사용해 보세요: 32개 유닛, 128개 유닛 등\n",
        "* 여기에서 두 개의 은닉층을 사용했습니다. 한 개의 은닉층이나 세 개의 은닉층을 사용해 보세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPqtM_sXG0pg"
      },
      "source": [
        "## 정리\n",
        "\n",
        "다음은 이 예제에서 배운 것들입니다.\n",
        "\n",
        "* N개의 클래스로 데이터 포인트를 분류하려면 네트워크의 마지막 `Dense` 층의 크기는 N이어야 합니다.\n",
        "* 단일 레이블, 다중 분류 문제에서는 N개의 클래스에 대한 확률 분포를 출력하기 위해 `softmax` 활성화 함수를 사용해야 합니다.\n",
        "* 이런 문제에는 항상 범주형 크로스엔트로피를 사용해야 합니다. 이 함수는 모델이 출력한 확률 분포와 타깃 분포 사이의 거리를 최소화합니다.\n",
        "* 다중 분류에서 레이블을 다루는 두 가지 방법이 있습니다.\n",
        "    * 레이블을 범주형 인코딩(또는 원-핫 인코딩)으로 인코딩하고 `categorical_crossentropy` 손실 함수를 사용합니다.\n",
        "    * 레이블을 정수로 인코딩하고 `sparse_categorical_crossentropy` 손실 함수를 사용합니다.\n",
        "* 많은 수의 범주를 분류할 때 중간층의 크기가 너무 작아 네트워크에 정보의 병목이 생기지 않도록 해야 합니다."
      ]
    }
  ]
}